\documentclass[a4paper]{article}

\renewcommand{\thesubsubsection}{\arabic{subsubsection}}

\title{IN2349 ADLR: Project Ideas}
\begin{document}
\maketitle

Here you can find a number of ideas for projects we collected. Take this as an inspiration for your own project. Some of the ideas are rather "big", meaning they could result in more than one project. After you have registered your team (including a draft proposal) you will discuss the extent of your final proposal with your assigned tutor.


\subsubsection{Learning the Inverse Kinematic}
Look at the possibilities for representing inverse problems with neural networks.
\textit{Analyzing Inverse Problems with Invertible Neural Networks}~\cite{Ardizzone2018}
compare different flavors of GANs, VAEs and INN(theirs) for inverse problems in general. Extend their simple robotic example of a planner arm to 3D / more DoFs / multiple TCPs.
\begin{itemize}
  \item What is the best approach to represent the high dimensional nullspaces for complex robot geometries?
  \item Predict not only the position of the TCP but also the rotation. Connection to continuous rotation representation ~\cite{Zhou2018}.
  \item How to measure the performance if the real nullspace is not known?
\end{itemize}

\subsubsection{Harnessing Reinforcement Learning for Neural Motion Planning}
Motion planning for a planar robotic arm from a start configuration to a cartesian goal position. Comparison between DDPG, DDPG+HER, and DDPG-MP(theirs) ~\cite{Jurgenson2019}.
They use RRT* to generate expert knowledge in difficult cases, where random exploration does not find a feasible solution.
\begin{itemize}
    \item Modify the code and try it for different robots and environments.
    \item They state that supervised learning is inferior to RL for this problem because of the insufficient data on the boundary of the obstacles. Is it possible to achieve similar results by tweaking the distribution of the supervised examples?
\end{itemize}


\subsubsection{Learning to Optimize Motion Planning}
Explore the ideas proposed by "Learning to Optimize" ~\cite{LiM16b} in the context of optimization based motion planning \cite{Zucker2013}. Can RL guide an optimzer to speed up robotic path planning?

\begin{itemize}
    \item Set up an optimizer for a simple robot (with help from the tutor)
    \item Test ideas to guide the optimizer with RL
    \item What are advantages of this hybrid approach over using RL directly on motion planning
    \end{itemize}


\bibliographystyle{apalike}
\bibliography{minimal-research}

\end{document}
